{
    "task": "jpeg"     //  color Gaussian denoising for noise level 15/25/50. root/task/images-models-options
    , "model": "plain" // "plain" | "plain2" if two inputs
    , "gpu_ids": [2, 3]
    , "dist": false
  
    , "n_channels": 3  // broadcast to "datasets", 1 for grayscale, 3 for color
  
    , "path": {
      "root": "check_points"            // "denoising" | "superresolution" | "dejpeg"
      , "pretrained_netG": null      // path of pretrained model
      , "pretrained_netE": null      // path of pretrained model
    }
  
    , "datasets": {
      "train": {
        "name": "train_dataset"           // just name
        , "dataset_type": "dncnn"         // "dncnn" | "dnpatch" | "fdncnn" | "ffdnet" | "sr" | "srmd" | "dpsr" | "plain" | "plainpatch" | "jpeg"
        , "dataroot_H": "../dataset/train/hq"// path of H training dataset. DIV2K (800 training images) + Flickr2K (2650 images) + BSD500 (400 training&testing images) + WED(4744 images) in SwinIR
        , "dataroot_L": "../dataset/train/jpeg/jpeg"             // path of L training dataset
  
        , "H_size": 512                   // patch_size
        , "sigma": 15                     //  15 | 25 | 50. We fine-tune sigma=25/50 models from sigma=15 model, so that `G_optimizer_lr` and `G_scheduler_milestones` can be halved to save time.
        , "sigma_test": 15                // 
  
        , "dataloader_shuffle": true
        , "dataloader_num_workers": 2
        , "dataloader_batch_size": 2      // batch size 1 | 16 | 32 | 48 | 64 | 128. Total batch size =1x8=8 in SwinIR
      }
    }
    , "netG": {
      "net_type": "STUNet" 
      , "upscale": 1 
      , "in_chans": 3 
      , "img_size": 512 
      , "window_size": 8  
      , "img_range": 1.0 
      , "embed_dim": 48 
      , "num_heads": [1, 2, 4, 8]
      , "mlp_ratio": 2 
      , "upsampler": null                 // "pixelshuffle" | "pixelshuffledirect" | "nearest+conv" | null
      , "resi_connection": "1conv"        // "1conv" | "3conv"
      , "init_type": "default"
    }
  
    , "train": {
      "G_lossfn_type": "l1"      // "l1" | "l2sum" | "l2" | "ssim" | "charbonnier" preferred
      , "G_lossfn_weight": 1.0            // default
      , "G_charbonnier_eps": 1e-9
      , "manual_seed": 1234
      , "E_decay": 0                 // Exponential Moving Average for netG: set 0 to disable; default setting 0.999
  
      , "G_optimizer_type": "adam"        // fixed, adam is enough
      , "G_optimizer_lr": 1e-3            // learning rate
      , "G_optimizer_wd": 0               // weight decay, default 0
      , "G_optimizer_clipgrad": null      // unused
      , "G_optimizer_reuse": true         // 
  
      , "G_scheduler_type": "MultiStepLR" // "MultiStepLR" is enough
      , "G_scheduler_milestones": [800000, 1200000, 1400000, 1500000, 1600000]
      , "G_scheduler_gamma": 0.5
  
      , "G_regularizer_orthstep": null    // unused
      , "G_regularizer_clipstep": null    // unused
  
      , "G_param_strict": true
      , "E_param_strict": true
  
      , "checkpoint_test": 2000      // for testing
      , "checkpoint_save": 20000         // for saving model
      , "checkpoint_print": 500           // for print
    }
  }